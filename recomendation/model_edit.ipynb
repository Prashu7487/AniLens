{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243d730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "# from tensorflow.keras.experimental import CosineDecayRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a6792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n",
    "# from tensorflow.keras.optimizers.schedules import PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26423e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 17:29:29.688694: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-04-18 17:29:29.688746: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-04-18 17:29:29.688760: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-04-18 17:29:29.689139: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-18 17:29:29.689698: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BS, n_users, embedding_size)\n",
      "(5, 20, 50)\n",
      "(BS, n_animes, embedding_size)\n",
      "(5, 10, 50)\n",
      "Dot product shape:\n",
      "(5, 20, 10)\n"
     ]
    }
   ],
   "source": [
    "# testing Dot layer for dot product\n",
    "x1 = Embedding(100, output_dim=50)(np.arange(100).reshape(5, 20))\n",
    "x2 = Embedding(100, output_dim=50)(np.arange(50).reshape(5, 10))\n",
    "dotted = Dot(axes=2)([x1, x2])\n",
    "print(\"(BS, n_users, embedding_size)\")\n",
    "print(x1.shape)\n",
    "print(\"(BS, n_animes, embedding_size)\")\n",
    "print(x2.shape)\n",
    "print(\"Dot product shape:\")\n",
    "print(dotted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c6d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_id_to_idx', 'user_idx_to_id', 'anime_id_to_idx', 'anime_idx_to_id'])\n",
      "CPU times: user 485 ms, sys: 31.4 ms, total: 516 ms\n",
      "Wall time: 519 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145311, 17562)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "\n",
    "ENCODER_PATH = 'encoder_dicts.joblib'\n",
    "encoders_dict = joblib.load(ENCODER_PATH)\n",
    "print(encoders_dict.keys())\n",
    "\n",
    "anime_id_to_idx = encoders_dict['anime_id_to_idx']\n",
    "anime_idx_to_id = encoders_dict['anime_idx_to_id']\n",
    "user_id_to_idx = encoders_dict['user_id_to_idx']\n",
    "user_idx_to_id = encoders_dict['user_idx_to_id']\n",
    "\n",
    "n_users, n_animes = len(user_id_to_idx), len(anime_id_to_idx)\n",
    "n_users, n_animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e5f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended embedding sizes by fastai: (600, 363)\n",
    "# reduced a lot here to make it simpler\n",
    "USER_EMB_SIZE = 128\n",
    "ANIME_EMB_SIZE = 128\n",
    "EMBEDDING_SIZES = (USER_EMB_SIZE, ANIME_EMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699d9223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# Accelerator check\n",
    "import tensorflow as tf\n",
    "\n",
    "TPU_INIT = False\n",
    "\n",
    "# if TPU_INIT:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "#     tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# else:\n",
    "#     !nvidia-smi\n",
    "if TPU_INIT:\n",
    "    try:\n",
    "        GPU = False\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    except ValueError:\n",
    "        TPU_INIT = False\n",
    "        GPU = True\n",
    "        print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
    "        tpu_strategy = tf.distribute.MirroredStrategy()\n",
    "        !nvidia-smi\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05cef7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LR = 1e-5  # minimum learning rate\n",
    "MAX_LR = 5e-4  # maximum learning rate\n",
    "BS = 10000  # batch_size\n",
    "EPOCHS = 10\n",
    "\n",
    "if TPU_INIT:\n",
    "    MAX_LR *= tpu_strategy.num_replicas_in_sync\n",
    "    BS *= tpu_strategy.num_replicas_in_sync\n",
    "    print(\"MAX_LR with TPU:\", MAX_LR)\n",
    "    print(\"batch_size with TPU:\", BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e161c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTIONAL_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4f06a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Subclassing API Model\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class RecommenderModel(Model):\n",
    "    # Based on https://keras.io/examples/structured_data/collaborative_filtering_movielens/\n",
    "    def __init__(self, n_users, n_animes, embedding_sizes, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_users = n_users\n",
    "        self.n_animes = n_animes\n",
    "        self.embedding_sizes = embedding_sizes\n",
    "        self.user_embedding = Embedding(\n",
    "            name='user_embedding',\n",
    "            input_dim=n_users,\n",
    "            output_dim=embedding_sizes[0],\n",
    "#             embeddings_initializer='he_normal',\n",
    "#             embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.anime_embedding = Embedding(\n",
    "            name='anime_embedding',\n",
    "            input_dim=n_animes,\n",
    "            output_dim=embedding_sizes[1],\n",
    "#             embeddings_initializer='he_normal',\n",
    "#             embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.dot_layer = Dot(name='dot_product', normalize=True, axes=1)\n",
    "        self.layers_ = [\n",
    "            Flatten(),\n",
    "        \n",
    "#             bias is not needed when using BatchNorm\n",
    "            Dense(128, activation=activation, use_bias=False, kernel_initializer='he_normal'),\n",
    "            BatchNormalization(),\n",
    "            Dense(64, activation=activation, use_bias=False, kernel_initializer='he_normal'),\n",
    "            BatchNormalization(),\n",
    "            Dense(1, use_bias=False, kernel_initializer='he_normal'),\n",
    "            BatchNormalization(),\n",
    "            Activation('sigmoid'),\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        anime_vector = self.anime_embedding(inputs[:, 1])\n",
    "#         x = tf.concat([user_vector, anime_vector], axis=1)\n",
    "        x = self.dot_layer([user_vector, anime_vector])\n",
    "#         x = tf.tensordot(user_vector, anime_vector, axis=2)\n",
    "        for layer in self.layers_:\n",
    "            x = layer(x)\n",
    "#         x = dot_user_anime + user_bias + anime_bias\n",
    "        return x\n",
    "\n",
    "def get_model():\n",
    "    print(\"[INFO] Using Subclassing API Model\")\n",
    "\n",
    "    # Resets all state generated by Keras to clear all models\n",
    "    K.clear_session()\n",
    "    \n",
    "    if TPU_INIT:\n",
    "        with tpu_strategy.scope():\n",
    "            model = RecommenderModel(n_users, n_animes, EMBEDDING_SIZES)\n",
    "    else:\n",
    "        model = RecommenderModel(n_users, n_animes, EMBEDDING_SIZES)\n",
    "\n",
    "#     optimizer = Adam(lr=MAX_LR)\n",
    "#     optimizer = Adam(lr=MAX_LR, decay=MAX_LR / EPOCHS)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['mae', 'mse'], optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "if not FUNCTIONAL_MODEL:\n",
    "    model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa5961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "K.clear_session()\n",
    "\n",
    "def RecommenderNet():\n",
    "    # from Chaitanya's notebook https://www.kaggle.com/chaitanya99/recommendation-system-cf-anime/notebook\n",
    "    embedding_size = 128\n",
    "    \n",
    "    user = Input(name = 'user', shape = [1])\n",
    "    user_embedding = Embedding(name = 'user_embedding',\n",
    "                       input_dim = n_users, \n",
    "                       output_dim = embedding_size)(user)\n",
    "    \n",
    "    anime = Input(name = 'anime', shape = [1])\n",
    "    anime_embedding = Embedding(name = 'anime_embedding',\n",
    "                       input_dim = n_animes, \n",
    "                       output_dim = embedding_size)(anime)\n",
    "    \n",
    "    # normalize=True will generate cosine similarity output\n",
    "    # axes=2 to perform matrix multiplication on embedding axes\n",
    "    x = Dot(name='dot_product', normalize=True, axes=2)([user_embedding, anime_embedding])\n",
    "    x = Flatten()(x)\n",
    "        \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=[user, anime], outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='Adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_functional_model():\n",
    "    print(\"[INFO] Using Functional API Model\")\n",
    "    if TPU_INIT:    \n",
    "        with tpu_strategy.scope():\n",
    "            model = RecommenderNet()\n",
    "    else:\n",
    "        model = RecommenderNet()\n",
    "    print(model.summary())\n",
    "    return model\n",
    "    \n",
    "    \n",
    "if FUNCTIONAL_MODEL:\n",
    "    model = get_functional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f619414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53454a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfe7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = 'weights.h5'\n",
    "def load_trained_model():\n",
    "    model = get_model()\n",
    "    print('Calling model to load layers...')\n",
    "    _ = model(tf.ones((1, 2)))\n",
    "    model.load_weights(WEIGHTS_PATH)\n",
    "    print('Loaded weights.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26dc7bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Subclassing API Model\n",
      "Calling model to load layers...\n",
      "Loaded weights.\n",
      "CPU times: user 202 ms, sys: 136 ms, total: 338 ms\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51715d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] There is no checkpoint file\n"
     ]
    }
   ],
   "source": [
    "# load the best weights\n",
    "try:\n",
    "    if os.path.exists(checkpoint_filepath):\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "except:\n",
    "    print(\"[INFO] There is no checkpoint file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f42c47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(name, model):\n",
    "    weight_layer = model.get_layer(name)\n",
    "    weights = weight_layer.get_weights()[0]\n",
    "    # because Dot layer was using normalize=True..?\n",
    "    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n",
    "    return weights\n",
    "\n",
    "anime_weights = extract_weights('anime_embedding', model)\n",
    "user_weights = extract_weights('user_embedding', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5bd563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17562, 128), (145311, 128))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_weights.shape, user_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6b685cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df = pd.read_csv('anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80e982bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df.sort_values('Name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6382c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anime_types = set(anime_df['Type'].unique())\n",
    "\n",
    "def check_anime_types(types):\n",
    "    types = set([types]) if isinstance(types, str) else set(types)\n",
    "    if types.issubset(all_anime_types):\n",
    "        return\n",
    "    else:\n",
    "        for anime_type in types:\n",
    "            if anime_type not in all_anime_types:\n",
    "                raise Exception(f'Anime type \"{anime_type}\" is not valid!')\n",
    "\n",
    "def get_anime_rows(df, anime_query, exact_name=False, types=None):\n",
    "    df = df.copy()\n",
    "    if isinstance(anime_query, int):\n",
    "        df = df[df.MAL_ID == anime_query]\n",
    "    else:\n",
    "        if exact_name:\n",
    "            # get exact name\n",
    "            df = df[df.Name == anime_query]\n",
    "        else:\n",
    "            df = df[df.Name.str.contains(anime_query, case=False, regex=False)]\n",
    "        \n",
    "    if types:\n",
    "        check_anime_types(types)\n",
    "        df = df[df.Type.isin(types)]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50493add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.reset_option('all')\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "def get_recommendation(anime_query, k=10, exact_name=False, types=None):\n",
    "    if types:\n",
    "        check_anime_types(types)\n",
    "    anime_rows = get_anime_rows(anime_df, anime_query, \n",
    "                               exact_name=exact_name)\n",
    "    if len(anime_rows) == 0:\n",
    "        raise Exception(f'Anime not found for {anime_query}')\n",
    "    anime_row = anime_rows.iloc[[0]]\n",
    "    anime_id = anime_row.MAL_ID.values[0]\n",
    "    anime_name = anime_row.Name.values[0]\n",
    "    anime_idx = anime_id_to_idx.get(anime_id)\n",
    "\n",
    "    weights = anime_weights\n",
    "#         dists = np.dot(anime_weights[anime_idx], user_weights.T)\n",
    "    distances = np.dot(weights, weights[anime_idx])\n",
    "\n",
    "    sorted_dists_ind = np.argsort(distances)[::-1]\n",
    "\n",
    "    print(f'Recommending animes for {anime_name}')\n",
    "    display(anime_row.loc[:, 'MAL_ID': 'Aired'])\n",
    "\n",
    "    anime_list = []\n",
    "    # [1:] to skip the first row for anime_query\n",
    "    for idx in sorted_dists_ind[1:]:\n",
    "        similarity = distances[idx]\n",
    "        anime_id = anime_idx_to_id.get(idx)\n",
    "        anime_row = anime_df[anime_df.MAL_ID == anime_id]\n",
    "        anime_type = anime_row.Type.values[0]\n",
    "        if types and anime_type not in types:\n",
    "            continue\n",
    "        anime_name = anime_row.Name.values[0]\n",
    "        score = anime_row.Score.values[0]\n",
    "        genre = anime_row.Genres.values[0]\n",
    "\n",
    "        anime_list.append({\"Anime_id\": anime_id, \"Name\": anime_name,\n",
    "                           \"Similarity\": similarity, \"Score\": score,\n",
    "                           \"Type\": anime_type, \"Genre\": genre\n",
    "                          })\n",
    "        if len(anime_list) == k:\n",
    "            # enough number of recommendations\n",
    "            break\n",
    "    rec_df = pd.DataFrame(anime_list)\n",
    "    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7c96f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending animes for Dragon Ball Super\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>English name</th>\n",
       "      <th>Japanese name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Aired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>30694</td>\n",
       "      <td>Dragon Ball Super</td>\n",
       "      <td>7.42</td>\n",
       "      <td>Action, Adventure, Comedy, Super Power, Martial Arts, Fantasy, Shounen</td>\n",
       "      <td>Dragon Ball Super</td>\n",
       "      <td>ドラゴンボール超（スーパー）</td>\n",
       "      <td>TV</td>\n",
       "      <td>131</td>\n",
       "      <td>Jul 5, 2015 to Mar 25, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAL_ID               Name Score  \\\n",
       "10623   30694  Dragon Ball Super  7.42   \n",
       "\n",
       "                                                                       Genres  \\\n",
       "10623  Action, Adventure, Comedy, Super Power, Martial Arts, Fantasy, Shounen   \n",
       "\n",
       "            English name   Japanese name Type Episodes  \\\n",
       "10623  Dragon Ball Super  ドラゴンボール超（スーパー）   TV      131   \n",
       "\n",
       "                             Aired  \n",
       "10623  Jul 5, 2015 to Mar 25, 2018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22777</td>\n",
       "      <td>Dragon Ball Kai (2014)</td>\n",
       "      <td>0.699218</td>\n",
       "      <td>7.69</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Adventure, Comedy, Super Power, Martial Arts, Fantasy, Shounen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31722</td>\n",
       "      <td>Nanatsu no Taizai: Seisen no Shirushi</td>\n",
       "      <td>0.650817</td>\n",
       "      <td>7.12</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Adventure, Ecchi, Fantasy, Magic, Shounen, Supernatural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34577</td>\n",
       "      <td>Nanatsu no Taizai: Imashime no Fukkatsu</td>\n",
       "      <td>0.646382</td>\n",
       "      <td>7.84</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Adventure, Fantasy, Magic, Shounen, Supernatural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24703</td>\n",
       "      <td>High School DxD BorN</td>\n",
       "      <td>0.609331</td>\n",
       "      <td>7.45</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Comedy, Demons, Ecchi, Harem, Romance, School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34281</td>\n",
       "      <td>High School DxD Hero</td>\n",
       "      <td>0.603054</td>\n",
       "      <td>7.28</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Comedy, Demons, Ecchi, Harem, Romance, School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22043</td>\n",
       "      <td>Fairy Tail (2014)</td>\n",
       "      <td>0.595496</td>\n",
       "      <td>7.73</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Adventure, Comedy, Fantasy, Magic, Shounen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19157</td>\n",
       "      <td>Youkai Watch</td>\n",
       "      <td>0.590198</td>\n",
       "      <td>6.54</td>\n",
       "      <td>TV</td>\n",
       "      <td>Comedy, Demons, Kids, Supernatural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21639</td>\n",
       "      <td>Yu☆Gi☆Oh! Arc-V</td>\n",
       "      <td>0.589715</td>\n",
       "      <td>6.79</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Game, Fantasy, Shounen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35964</td>\n",
       "      <td>Basilisk: Ouka Ninpouchou</td>\n",
       "      <td>0.586572</td>\n",
       "      <td>5.47</td>\n",
       "      <td>TV</td>\n",
       "      <td>Action, Drama, Historical, Martial Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33834</td>\n",
       "      <td>Sin: Nanatsu no Taizai</td>\n",
       "      <td>0.586406</td>\n",
       "      <td>5.69</td>\n",
       "      <td>TV</td>\n",
       "      <td>Ecchi, Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anime_id                                     Name  Similarity Score Type  \\\n",
       "0     22777                   Dragon Ball Kai (2014)    0.699218  7.69   TV   \n",
       "1     31722    Nanatsu no Taizai: Seisen no Shirushi    0.650817  7.12   TV   \n",
       "2     34577  Nanatsu no Taizai: Imashime no Fukkatsu    0.646382  7.84   TV   \n",
       "3     24703                     High School DxD BorN    0.609331  7.45   TV   \n",
       "4     34281                     High School DxD Hero    0.603054  7.28   TV   \n",
       "5     22043                        Fairy Tail (2014)    0.595496  7.73   TV   \n",
       "6     19157                             Youkai Watch    0.590198  6.54   TV   \n",
       "7     21639                          Yu☆Gi☆Oh! Arc-V    0.589715  6.79   TV   \n",
       "8     35964                Basilisk: Ouka Ninpouchou    0.586572  5.47   TV   \n",
       "9     33834                   Sin: Nanatsu no Taizai    0.586406  5.69   TV   \n",
       "\n",
       "                                                                    Genre  \n",
       "0  Action, Adventure, Comedy, Super Power, Martial Arts, Fantasy, Shounen  \n",
       "1         Action, Adventure, Ecchi, Fantasy, Magic, Shounen, Supernatural  \n",
       "2                Action, Adventure, Fantasy, Magic, Shounen, Supernatural  \n",
       "3                   Action, Comedy, Demons, Ecchi, Harem, Romance, School  \n",
       "4                   Action, Comedy, Demons, Ecchi, Harem, Romance, School  \n",
       "5                      Action, Adventure, Comedy, Fantasy, Magic, Shounen  \n",
       "6                                      Comedy, Demons, Kids, Supernatural  \n",
       "7                                          Action, Game, Fantasy, Shounen  \n",
       "8                                 Action, Drama, Historical, Martial Arts  \n",
       "9                                                          Ecchi, Fantasy  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation('Dragon Ball Super', 10, types=('TV', 'Movie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab73ca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
